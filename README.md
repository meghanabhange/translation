# Pay Attention to The Translations âœ¨

## Demo

PLACEHOLDER

## How To Run The Demo Locally

*Installations*

```
pip install requirements.py
```

*Getting Data*

The trained models are available as GitHub Releases with the repository. 

```
python -m download OUTPUT_DIR
```

*Running App*

``
streamlit run seq2seq/app.py
``

## Evaluation 

```
pip install requirements.py
python -m download OUTPUT_DIR
python -m predictandevaluate OUTPUT_DIR
```
---

# Notebooks 

- 1. Experiment 1. Transformer Seq2Seq model using attention 
- 2. Experiment 2. T5 translation model

# Metrics 

## 1. Experiment 1. Transformer Seq2Seq model using attention 

- BLEU : 
- BERTScore : 
- WER (Word Error Rate) : 

## 2. Experiment 2. T5 translation model

- BLEU : 
- BERTScore : 
- WER (Word Error Rate) : 